{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "gan-base.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgucBxMyd7hL",
        "outputId": "a3734cca-c5ee-44c7-9705-5a237274d5ba"
      },
      "source": [
        "from google.colab import drive\n",
        "#Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "base_path = './drive/MyDrive/Colab Notebooks/Data/ML/HW5/'"
      ],
      "id": "pgucBxMyd7hL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "racial-lodge"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "id": "racial-lodge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "supported-pontiac"
      },
      "source": [
        "# Define learning parameters"
      ],
      "id": "supported-pontiac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absolute-country"
      },
      "source": [
        "# learning parameters\n",
        "batch_size = 512\n",
        "# batch_size = 256 #For Q1(c)\n",
        "epochs = 100\n",
        "sample_size = 64 # fixed sample size for generator\n",
        "nz = 128 # latent vector size\n",
        "k = 1 # number of steps to apply to the discriminator\n",
        "# k = 3 #For Q1(c)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "absolute-country",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intellectual-tenant"
      },
      "source": [
        "# Prepare training dataset"
      ],
      "id": "intellectual-tenant"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opposite-hundred"
      },
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "to_pil_image = transforms.ToPILImage()\n",
        "\n",
        "# Make input, output folders\n",
        "!mkdir -p input\n",
        "!mkdir -p outputs\n",
        "\n",
        "# Load train data\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ],
      "id": "opposite-hundred",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aboriginal-guitar"
      },
      "source": [
        "# Generator"
      ],
      "id": "aboriginal-guitar"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "speaking-diary"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(self.nz, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)"
      ],
      "id": "speaking-diary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "later-democracy"
      },
      "source": [
        "# Discriminator"
      ],
      "id": "later-democracy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "silent-zealand"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.n_input = 784\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(self.n_input, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.main(x)"
      ],
      "id": "silent-zealand",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daily-palestine",
        "outputId": "9d0abb6a-7840-4d8d-8005-d4e43ee09613"
      },
      "source": [
        "generator = Generator(nz).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "print('##### GENERATOR #####')\n",
        "print(generator)\n",
        "print('######################')\n",
        "print('\\n##### DISCRIMINATOR #####')\n",
        "print(discriminator)\n",
        "print('######################')"
      ],
      "id": "daily-palestine",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### GENERATOR #####\n",
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (7): Tanh()\n",
            "  )\n",
            ")\n",
            "######################\n",
            "\n",
            "##### DISCRIMINATOR #####\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2)\n",
            "    (8): Dropout(p=0.3, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (10): Sigmoid()\n",
            "  )\n",
            ")\n",
            "######################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moral-brooks"
      },
      "source": [
        "# Tools for training"
      ],
      "id": "moral-brooks"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moved-lawyer"
      },
      "source": [
        "# optimizers\n",
        "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)"
      ],
      "id": "moved-lawyer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irish-allen"
      },
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss() # Binary Cross Entropy loss"
      ],
      "id": "irish-allen",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suited-fishing"
      },
      "source": [
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "images = [] # to store images generatd by the generator"
      ],
      "id": "suited-fishing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-heater"
      },
      "source": [
        "# to create real labels (1s)\n",
        "def label_real(size):\n",
        "    data = torch.ones(size, 1)\n",
        "    return data.to(device)\n",
        "# to create fake labels (0s)\n",
        "def label_fake(size):\n",
        "    data = torch.zeros(size, 1)\n",
        "    return data.to(device)\n"
      ],
      "id": "sensitive-heater",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "australian-apollo"
      },
      "source": [
        "# function to create the noise vector\n",
        "def create_noise(sample_size, nz):\n",
        "    return torch.randn(sample_size, nz).to(device)"
      ],
      "id": "australian-apollo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extraordinary-roller"
      },
      "source": [
        "# to save the images generated by the generator\n",
        "def save_generator_image(image, path):\n",
        "    save_image(image, path)"
      ],
      "id": "extraordinary-roller",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "greatest-landing"
      },
      "source": [
        "# create the noise vector - fixed to track how GAN is trained.\n",
        "noise = create_noise(sample_size, nz)"
      ],
      "id": "greatest-landing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3hfmBbynyqt"
      },
      "source": [
        "60000%512"
      ],
      "id": "_3hfmBbynyqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jth63OE0btHx"
      },
      "source": [
        ""
      ],
      "id": "Jth63OE0btHx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rocky-theme"
      },
      "source": [
        "# Q. Write training loop"
      ],
      "id": "rocky-theme"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beginning-champagne"
      },
      "source": [
        "torch.manual_seed(7777)\n",
        "import pdb\n",
        "def generator_loss(output, true_label):\n",
        "    ############ YOUR CODE HERE ##########\n",
        "    \n",
        "    return criterion(output,true_label)\n",
        "    \n",
        "    \n",
        "    ######################################\n",
        "    \n",
        "def discriminator_loss(output, true_label):\n",
        "    ############ YOUR CODE HERE ##########\n",
        "    return criterion(output,true_label)\n",
        "    \n",
        "    \n",
        "    ######################################\n",
        "    \n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_g = 0.0\n",
        "    loss_d = 0.0\n",
        "    print(\"epoch ----\" + str(epoch))\n",
        "    switch = 1\n",
        "    for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
        "        real_images = data[0].to(device)  # Place imagery on GPU (if present)\n",
        "        ############ YOUR CODE HERE ########## \n",
        "        noise_batch = create_noise(len(real_images), nz)\n",
        "\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "\n",
        "        optim_d.zero_grad()\n",
        "        # pdb.set_trace()\n",
        "        # print(\"********\" + str(len(real_images)))\n",
        "        # break\n",
        "        real_discriminator_loss = criterion(discriminator.forward(real_images), label_real(len(real_images)))\n",
        "\n",
        "        \n",
        "        # G(z) | G == generator and z == noise \n",
        "        fake_images = generator.forward(noise_batch)\n",
        "        # D(G(z)), we call detach() so that we don't calculate gradients for the generator during backward() \n",
        "        \n",
        "        fake_images_predictions = discriminator.forward(fake_images.detach())\n",
        "\n",
        "        fake_discriminator_loss = criterion(fake_images_predictions, label_fake(len(real_images)))\n",
        "\n",
        "        discriminator_loss = (real_discriminator_loss + fake_discriminator_loss)\n",
        "        loss_d += discriminator_loss\n",
        "        discriminator_loss.backward()\n",
        "        optim_d.step()\n",
        "\n",
        " \n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "\n",
        "        optim_g.zero_grad()\n",
        "\n",
        "        generated_images_predictions = discriminator.forward(generator.forward(noise_batch))\n",
        "\n",
        "        fake_generator_loss = criterion(generated_images_predictions, label_real(len(real_images)))\n",
        "        \"\"\"\n",
        "        Ques 1(b) for Grad descent - log(1-D(G(z))) - Commented out for original run.\n",
        "\n",
        "        fake_generator_loss = criterion(generated_images_predictions, label_fake(len(real_images)))\n",
        "        (-fake_generator_loss).backward()\n",
        "        \"\"\"\n",
        "        fake_generator_loss.backward()\n",
        "        loss_g += fake_generator_loss\n",
        "\n",
        "        optim_g.step()\n",
        "        ######################################\n",
        "    \n",
        "    \n",
        "    # create the final fake image for the epoch\n",
        "    generated_img = generator(noise).cpu().detach()\n",
        "    \n",
        "    # make the images as grid\n",
        "    generated_img = make_grid(generated_img)\n",
        "    \n",
        "    # visualize generated images\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 1:\n",
        "        plt.imshow(generated_img.permute(1, 2, 0))\n",
        "        plt.title(f'epoch {epoch+1}')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    \n",
        "    # save the generated torch tensor models to disk\n",
        "    save_generator_image(generated_img, f\"outputs/gen_img{epoch+1}.png\")\n",
        "    images.append(generated_img)\n",
        "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
        "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
        "    losses_g.append(epoch_loss_g)\n",
        "    losses_d.append(epoch_loss_d)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")"
      ],
      "id": "beginning-champagne",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chief-jewelry"
      },
      "source": [
        "print('DONE TRAINING')\n",
        "torch.save(generator.state_dict(), 'outputs/generator.pth')"
      ],
      "id": "chief-jewelry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relative-certificate"
      },
      "source": [
        "# save the generated images as GIF file\n",
        "imgs = [np.array(to_pil_image(img)) for img in images]\n",
        "imageio.mimsave('outputs/generator_images.gif', imgs)"
      ],
      "id": "relative-certificate",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh2PXf5Cabe0"
      },
      "source": [
        ""
      ],
      "id": "Lh2PXf5Cabe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liable-toronto"
      },
      "source": [
        "# plot and save the generator and discriminator loss\n",
        "plt.figure()\n",
        "plt.plot(losses_g, label='Generator loss')\n",
        "plt.plot(losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('outputs/loss.png')"
      ],
      "id": "liable-toronto",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adjusted-brother"
      },
      "source": [
        ""
      ],
      "id": "adjusted-brother",
      "execution_count": null,
      "outputs": []
    }
  ]
}